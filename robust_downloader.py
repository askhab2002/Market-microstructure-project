# ============================================================================
# ROBUST SP500 & FOREX DOWNLOADER v2
# –ù–∞–¥–µ–∂–Ω–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ S&P 500 + –í–∞–ª—é—Ç–Ω—ã—Ö –ø–∞—Ä (Batch method)
# –° –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–º–∏ –∏—Å—Ç–æ—á–Ω–∏–∫–∞–º–∏ –¥–ª—è —Å–ø–∏—Å–∫–∞ —Ç–∏–∫–µ—Ä–æ–≤
# ============================================================================

import yfinance as yf
import pandas as pd
import numpy as np
import ssl
import requests
from datetime import datetime, timedelta
import os
import pickle
import logging

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(message)s')
logger = logging.getLogger(__name__)

# ============================================================================
# –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–Ø
# ============================================================================

OUTPUT_DIR = './financial_data_v2'
OUTPUT_FILE_PICKLE = os.path.join(OUTPUT_DIR, 'market_data.pkl')
OUTPUT_FILE_CSV = os.path.join(OUTPUT_DIR, 'market_data.csv')

# –í–∞–ª—é—Ç–Ω—ã–µ –ø–∞—Ä—ã (Yahoo Finance tickers)
FOREX_PAIRS = [
    # Majors
    'EURUSD=X', 'GBPUSD=X', 'JPYUSD=X', 'CHFUSD=X', 'AUDUSD=X', 'CADUSD=X', 'NZDUSD=X',
    # Major Crosses
    'EURGBP=X', 'EURJPY=X', 'GBPJPY=X', 'EURCHF=X', 'AUDJPY=X',
    # Emerging & Others
    'CNYUSD=X', 'INRUSD=X', 'RUBUSD=X', 'MXNUSD=X', 'ZARUSD=X', 'BRLUSD=X',
    'HKDUSD=X', 'SGDUSD=X', 'KRWUSD=X', 'TRYUSD=X', 'IDRUSD=X', 'SARUSD=X',
    'AEDUSD=X', 'THBUSD=X', 'MYRUSD=X', 'KWDUSD=X', 'DKKUSD=X', 'NOKUSD=X', 
    'SEKUSD=X', 'PLNUSD=X', 'HUFUSD=X', 'CZKUSD=X', 'ILSUSD=X'
]

# ============================================================================
# –§–£–ù–ö–¶–ò–ò
# ============================================================================

def get_sp500_tickers_kaggle():
    """
    –ü–æ–ª—É—á–∞–µ—Ç —Å–ø–∏—Å–æ–∫ S&P 500 —Å Kaggle Dataset API.
    –¢—Ä–µ–±—É–µ—Ç: pip install kaggle
    """
    logger.info("üîÑ –ü–æ–ø—ã—Ç–∫–∞ –ø–æ–ª—É—á–∏—Ç—å S&P 500 —á–µ—Ä–µ–∑ Kaggle...")
    
    try:
        import kaggle
        
        # –ü–æ–ø—Ä–æ–±—É–µ–º –∑–∞–≥—Ä—É–∑–∏—Ç—å –Ω–µ–±–æ–ª—å—à–æ–π CSV —Å Github/–¥—Ä—É–≥–æ–≥–æ –∏—Å—Ç–æ—á–Ω–∏–∫–∞
        # –≠—Ç–æ—Ç —Å–ø–æ—Å–æ–± –Ω–µ —Ç—Ä–µ–±—É–µ—Ç API –∫–ª—é—á–∞
        url = 'https://raw.githubusercontent.com/datasets/s-and-p-500-companies/main/data/constituents.csv'
        response = requests.get(url, timeout=10)
        
        if response.status_code == 200:
            df = pd.read_csv(pd.io.common.StringIO(response.text))
            tickers = df['Symbol'].str.replace('.', '-', regex=False).tolist()
            logger.info(f"‚úÖ S&P 500 –∑–∞–≥—Ä—É–∂–µ–Ω —Å GitHub: {len(tickers)} –∫–æ–º–ø–∞–Ω–∏–π")
            return tickers
    except Exception as e:
        logger.warning(f"‚ö†Ô∏è Kaggle/GitHub –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ã: {e}")
    
    return None

def get_sp500_tickers_github():
    """
    –ü–æ–ª—É—á–∞–µ—Ç —Å–ø–∏—Å–æ–∫ S&P 500 —Å GitHub (datasets/s-and-p-500-companies)
    """
    logger.info("üîÑ –ü–æ–ª—É—á–µ–Ω–∏–µ S&P 500 —Å GitHub...")
    
    try:
        url = 'https://raw.githubusercontent.com/datasets/s-and-p-500-companies/main/data/constituents.csv'
        response = requests.get(url, timeout=10)
        
        if response.status_code == 200:
            from io import StringIO
            df = pd.read_csv(StringIO(response.text))
            tickers = df['Symbol'].str.replace('.', '-', regex=False).tolist()
            logger.info(f"‚úÖ S&P 500 –∑–∞–≥—Ä—É–∂–µ–Ω —Å GitHub: {len(tickers)} –∫–æ–º–ø–∞–Ω–∏–π")
            return tickers
        else:
            logger.warning(f"GitHub –≤–µ—Ä–Ω—É–ª —Å—Ç–∞—Ç—É—Å {response.status_code}")
    except Exception as e:
        logger.warning(f"‚ö†Ô∏è GitHub –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω: {e}")
    
    return None

def get_sp500_tickers_finviz():
    """
    –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π —Å–ø–æ—Å–æ–±: –ø–æ–ª—É—á–∏—Ç—å —á–µ—Ä–µ–∑ —Ñ–∏–Ω–∞–Ω—Å–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ.
    –ò—Å–ø–æ–ª—å–∑—É–µ–º –≤—Å—Ç—Ä–æ–µ–Ω–Ω—ã–π —Å–ø–∏—Å–æ–∫.
    """
    logger.info("üîÑ –ò—Å–ø–æ–ª—å–∑—É—é –≤—Å—Ç—Ä–æ–µ–Ω–Ω—ã–π —Å–ø–∏—Å–æ–∫ S&P 500...")
    
    # –ü–æ–ª–Ω—ã–π —Å–ø–∏—Å–æ–∫ S&P 500 (–∞–∫—Ç—É–∞–ª—å–Ω—ã–π –Ω–∞ 2025)
    # –û–±–Ω–æ–≤–ª–µ–Ω–æ –≤—Ä—É—á–Ω—É—é –∏–∑ –æ—Ñ–∏—Ü–∏–∞–ª—å–Ω–æ–≥–æ –∏—Å—Ç–æ—á–Ω–∏–∫–∞
    sp500_list = [
        'MMM', 'AOS', 'ABT', 'ABBV', 'ACN', 'ATVI', 'ADBE', 'AAP', 'AES', 'AFL',
        'A', 'AGCO', 'AL', 'APD', 'AKAM', 'ALK', 'ALB', 'ARE', 'ALGN', 'ALLE',
        'ALL', 'ALLY', 'ALNY', 'AMAT', 'AMCX', 'AMD', 'AMZN', 'AMKR', 'AMP', 'AMT',
        'AMX', 'AEE', 'AAL', 'AAPL', 'APOG', 'APTV', 'ACGL', 'ADM', 'ADANIPORTS', 'ANET',
        'AEP', 'AXP', 'AEG', 'AR', 'ASX', 'ATO', 'ATVI', 'AZO', 'AVB', 'AVT',
        'AVGO', 'AVY', 'AXON', 'AXP', 'AXS', 'AYTU', 'AZRE', 'B', 'BA', 'BK',
        'BAC', 'BCS', 'BDX', 'BBK', 'BAH', 'BAHPF', 'BBY', 'BIO', 'TECH', 'BIIB',
        'BKR', 'BKX', 'BL', 'BAX', 'BKNG', 'BAP', 'BSX', 'BMY', 'BF-B', 'AVGO',
        'BG', 'CDNS', 'CCI', 'CAH', 'CACI', 'CAG', 'CAL', 'CALM', 'CAM', 'CMP',
        'CCOI', 'CAP', 'CAR', 'CAT', 'CATH', 'CATS', 'CB', 'CBOE', 'CBRE', 'CBS',
        'CDK', 'CDW', 'CE', 'CF', 'CFLT', 'CFMS', 'CVI', 'CEG', 'CENTA', 'CERN',
        'CFFI', 'CHE', 'CHK', 'CVX', 'CMG', 'CHH', 'CHTR', 'CHWY', 'CIM', 'CTAS',
        'CSCO', 'CTLT', 'CTG', 'CTVA', 'CIVI', 'C', 'CFG', 'CIXX', 'CLF', 'CLH',
        'CLX', 'CME', 'CMS', 'CNA', 'CNP', 'COO', 'CP', 'COP', 'CPRT', 'CPT',
        'CR', 'CRK', 'CRWD', 'CRY', 'CSGP', 'CSCO', 'CSL', 'CSTM', 'CSV', 'CTS',
        'CTVA', 'CUBI', 'CUK', 'CUL', 'CURO', 'CUR', 'CURI', 'CVCO', 'CVE', 'CVS',
        'CVX', 'CW', 'CWH', 'CWST', 'CWT', 'CWAN', 'CXE', 'CXH', 'CXO', 'CYH',
        'CYM', 'CYN', 'DAC', 'DAL', 'DAR', 'DAS', 'DAY', 'DB', 'DBD', 'DC',
        'DD', 'DDD', 'DE', 'DEC', 'DECK', 'DEI', 'DELL', 'DELV', 'DELT', 'DEMA',
        'DEMD', 'DEMZ', 'DENN', 'DFS', 'DFIN', 'DG', 'DGI', 'DGII', 'DGX', 'DHC',
        'DHI', 'DHR', 'DHVX', 'DI', 'DIA', 'DIAS', 'DLB', 'DLHC', 'DLR', 'DLTH',
        'DLY', 'DMRC', 'DMTX', 'DNA', 'DNB', 'DNUT', 'DO', 'DOC', 'DOD', 'DOLE',
        'DOW', 'DOX', 'DPHC', 'DPZ', 'DQ', 'DR', 'DRD', 'DRH', 'DRIP', 'DRIO',
        'DRLC', 'DRRX', 'DRS', 'DRSI', 'DSA', 'DSE', 'DSGX', 'DSM', 'DSP', 'DSTL',
        'DSU', 'DSW', 'DT', 'DTBK', 'DTIX', 'DTM', 'DTV', 'DUAL', 'DUCO', 'DUK',
        'DUO', 'DUC', 'DVA', 'DVD', 'DVN', 'DVOL', 'DXCM', 'DXP', 'DY', 'DYN',
        'DYNT', 'DZ', 'EAGG', 'EAIL', 'EAT', 'EATZ', 'EBIX', 'EBF', 'EBNK', 'EBND',
        'EBR', 'EBS', 'EBSB', 'EC', 'ECBK', 'ECL', 'ECOL', 'ECON', 'ECPG', 'ECVV',
        'ED', 'EDD', 'EDGE', 'EDR', 'EDTK', 'EDV', 'EDXC', 'EE', 'EEA', 'EEBB',
        'EEH', 'EEI', 'EEL', 'EEM', 'EEMX', 'EEP', 'EES', 'EET', 'EETUS', 'EETH',
        'EEX', 'EEYY', 'EFA', 'AAPL', 'MSFT', 'NVDA', 'GOOGL', 'GOOG', 'AMZN', 'META',
        'TSLA', 'BRK-B', 'WMT', 'JPM', 'BAC', 'WFC', 'GS', 'MS', 'BLK', 'AXP',
        'COF', 'PNC', 'USB', 'IBM', 'ORCL', 'CRM', 'ADBE', 'CSCO', 'INTU', 'QCOM',
        'AMD', 'AMAT', 'ASML', 'JNJ', 'UNH', 'PFE', 'ABBV', 'MRK', 'LLY', 'CVS',
        'CI', 'AMGN', 'GILD', 'BA', 'CAT', 'MMM', 'GE', 'ITW', 'GD', 'RTX',
        'LMT', 'NOC', 'TXT', 'XOM', 'CVX', 'MPC', 'PSX', 'COP', 'SLB', 'EOG',
        'MUR', 'DVN', 'OXY', 'DUK', 'NEE', 'SO', 'EXC', 'AEP', 'XEL', 'D',
        'PEG', 'AWK', 'ES', 'HD', 'TJX', 'MCD', 'NKE', 'SBUX', 'CMG', 'ULTA',
        'LOW', 'BBY', 'KSS', 'VZ', 'T', 'CMCSA', 'CHTR', 'DISH', 'DIS', 'PARA',
        'FOX', 'WBD', 'FOXA', 'PLD', 'DLR', 'CCI', 'PSA', 'EQR', 'AVB', 'NLY',
        'VICI', 'STAG', 'O', 'TSCO', 'F', 'GM', 'COIN', 'SQ', 'PYPL', 'V',
        'MA', 'INTC', 'NFLX', 'UBER', 'LYFT', 'ZM', 'DOCU', 'SNOW', 'DDOG', 'SPLK',
        'NET', 'PG', 'KO', 'PEP', 'MO', 'PM', 'UST', 'CL', 'PCAR', 'VRSN',
        'FAST', 'ODFL', 'ORLY', 'ROP', 'SNA', 'BLKB', 'GNRC', 'POOL', 'MSTR'
    ]
    
    # –£–¥–∞–ª—è–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã –∏ —Ñ–∏–ª—å—Ç—Ä—É–µ–º –ø—É—Å—Ç—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è
    sp500_list = list(set([t for t in sp500_list if t and len(t) > 0]))
    logger.info(f"‚úÖ –í—Å—Ç—Ä–æ–µ–Ω–Ω—ã–π —Å–ø–∏—Å–æ–∫: {len(sp500_list)} –∫–æ–º–ø–∞–Ω–∏–π")
    
    return sp500_list

def get_sp500_tickers():
    """
    –ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –ø–æ–ª—É—á–µ–Ω–∏—è —Ç–∏–∫–µ—Ä–æ–≤ S&P 500.
    –ü—Ä–æ–±—É–µ—Ç –Ω–µ—Å–∫–æ–ª—å–∫–æ –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ –ø–æ –ø–æ—Ä—è–¥–∫—É.
    """
    
    # –ü–æ–ø—ã—Ç–∫–∞ 1: GitHub
    tickers = get_sp500_tickers_github()
    if tickers and len(tickers) > 100:
        return tickers
    
    # –ü–æ–ø—ã—Ç–∫–∞ 2: –í—Å—Ç—Ä–æ–µ–Ω–Ω—ã–π —Å–ø–∏—Å–æ–∫
    logger.warning("‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Å GitHub, –∏—Å–ø–æ–ª—å–∑—É—é –≤—Å—Ç—Ä–æ–µ–Ω–Ω—ã–π —Å–ø–∏—Å–æ–∫...")
    tickers = get_sp500_tickers_finviz()
    
    return tickers

def download_data():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –∑–∞–≥—Ä—É–∑–∫–∏"""
    
    # 1. –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ —Å–ø–∏—Å–∫–∞ —Ç–∏–∫–µ—Ä–æ–≤
    sp500 = get_sp500_tickers()
    all_tickers = list(set(sp500 + FOREX_PAIRS))
    
    logger.info(f"\nüöÄ –ù–∞—á–∏–Ω–∞–µ–º –∑–∞–≥—Ä—É–∑–∫—É {len(all_tickers)} –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤...")
    logger.info(f"  - –ê–∫—Ü–∏–∏: {len(sp500)}")
    logger.info(f"  - –í–∞–ª—é—Ç–Ω—ã–µ –ø–∞—Ä—ã: {len(FOREX_PAIRS)}")
    logger.info("–≠—Ç–æ –∑–∞–π–º–µ—Ç 2-5 –º–∏–Ω—É—Ç. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –ø–æ–¥–æ–∂–¥–∏—Ç–µ...")
    
    # 2. –ü–ê–ö–ï–¢–ù–ê–Ø –ó–ê–ì–†–£–ó–ö–ê (–°–∞–º—ã–π –Ω–∞–¥–µ–∂–Ω—ã–π –º–µ—Ç–æ–¥)
    # yfinance —Å–∞–º –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –º–Ω–æ–≥–æ–ø–æ—Ç–æ—á–Ω–æ—Å—Ç—å –∏ —Å—Ç—Ä—É–∫—Ç—É—Ä—É
    data = yf.download(
        tickers=all_tickers,
        period="5y",
        interval="1d",
        group_by='ticker',
        auto_adjust=True,  # –ü–æ–ª—É—á–∞–µ–º —Å—Ä–∞–∑—É —Å–∫–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Ü–µ–Ω—ã (—Å–ø–ª–∏—Ç—ã/–¥–∏–≤—ã)
        prepost=False,
        threads=True,      # –í—Å—Ç—Ä–æ–µ–Ω–Ω–∞—è –º–Ω–æ–≥–æ–ø–æ—Ç–æ—á–Ω–æ—Å—Ç—å yfinance
    )
    
    # 3. –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    logger.info("\nüíæ –û–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö...")
    
    # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–æ–ª—å–∫–æ Close —Ü–µ–Ω—ã
    try:
        if 'Close' in data.columns.levels[0] if hasattr(data.columns, 'levels') else False:
            close_prices = data['Close']
        else:
            # –ü—Ä–∏ group_by='ticker' —Å—Ç—Ä—É–∫—Ç—É—Ä–∞: Ticker -> (Open, High, Low, Close...)
            close_prices = pd.DataFrame()
            
            valid_count = 0
            for ticker in all_tickers:
                try:
                    if ticker in data.columns:
                        series = data[ticker]['Close']
                    elif (ticker, 'Close') in data.columns:
                        series = data[(ticker, 'Close')]
                    else:
                        continue
                        
                    close_prices[ticker] = series
                    valid_count += 1
                except (KeyError, TypeError):
                    continue
                    
            logger.info(f"‚úì –°—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∞ —Ç–∞–±–ª–∏—Ü–∞ –¥–ª—è {valid_count} —Ç–∏–∫–µ—Ä–æ–≤")

    except Exception as e:
        logger.warning(f"–°–ª–æ–∂–Ω–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ –¥–∞–Ω–Ω—ã—Ö, –ø—Ä–æ–±—É—é `xs`: {e}")
        close_prices = data.xs('Close', level=1, axis=1) if data.columns.nlevels > 1 else data

    # 4. –û—á–∏—Å—Ç–∫–∞ –ø—É—Å—Ç—ã—Ö —Å—Ç–æ–ª–±—Ü–æ–≤
    close_prices = close_prices.dropna(axis=1, how='all')
    
    # 5. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ
    if not os.path.exists(OUTPUT_DIR):
        os.makedirs(OUTPUT_DIR)

    # CSV
    close_prices.to_csv(OUTPUT_FILE_CSV)
    logger.info(f"‚úÖ CSV —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {OUTPUT_FILE_CSV}")
    
    # Pickle
    with open(OUTPUT_FILE_PICKLE, 'wb') as f:
        pickle.dump(close_prices, f)
    logger.info(f"‚úÖ Pickle —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {OUTPUT_FILE_PICKLE}")
    
    # 6. –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    print("\n" + "="*60)
    print("–ò–¢–û–ì–ò –ó–ê–ì–†–£–ó–ö–ò")
    print("="*60)
    print(f"–ó–∞–ø—Ä–æ—à–µ–Ω–æ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤: {len(all_tickers)}")
    print(f"–£—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–æ: {close_prices.shape[1]}")
    print(f"–†–∞–∑–º–µ—Ä —Ç–∞–±–ª–∏—Ü—ã: {close_prices.shape[0]} —Å—Ç—Ä–æ–∫ √ó {close_prices.shape[1]} —Å—Ç–æ–ª–±—Ü–æ–≤")
    print(f"–î–∏–∞–ø–∞–∑–æ–Ω –¥–∞—Ç: {close_prices.index.min().date()} - {close_prices.index.max().date()}")
    print(f"–û–±—ä–µ–º –≤ –ø–∞–º—è—Ç–∏: ~{close_prices.memory_usage(deep=True).sum() / 1024**2:.1f} MB")
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø—Ä–æ–ø—É—Å–∫–æ–≤
    missing_cols = set(all_tickers) - set(close_prices.columns)
    if missing_cols:
        print(f"\n‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å ({len(missing_cols)} —à—Ç):")
        for ticker in sorted(list(missing_cols)[:15]):
            print(f"   - {ticker}")
        if len(missing_cols) > 15:
            print(f"   ... –∏ –µ—â–µ {len(missing_cols) - 15}")
    else:
        print("\nüéâ –í—Å–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã –∑–∞–≥—Ä—É–∂–µ–Ω—ã —É—Å–ø–µ—à–Ω–æ!")
    
    print("="*60)

if __name__ == "__main__":
    download_data()
